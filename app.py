import requests
import json
import time
from collections import defaultdict
from rediscluster import RedisCluster, RedisClusterException

# ======================================
# âš™ï¸ Cáº¥u hÃ¬nh
# ======================================
URL = "https://spine-mri-public-data.s3.ap-southeast-1.amazonaws.com/transformed/cleaned_mri_data.json"

# Redis Cluster nodes
startup_nodes = [
    {"host": "127.0.0.1", "port": "7001"},
    {"host": "127.0.0.1", "port": "7002"},
    {"host": "127.0.0.1", "port": "7003"},
]

# Káº¿t ná»‘i tá»›i Redis Cluster
try:
    # Initialize the Redis Cluster client
    # Add password if needed: password="your_password"
    r = RedisCluster(startup_nodes=startup_nodes, decode_responses=True, skip_full_coverage_check=True)

    # Test the connection
    print("Connection successful:", r.ping())

    # Example usage:
    r.set("foo", "bar")
    print(r.get("foo"))

except RedisClusterException as e:
    print(f"Redis Cluster connection failed: {e}")
    # Additional logging or error handling here
except Exception as e:
    print(f"An unexpected error occurred: {e}")
    

# ======================================
# ğŸ“¥ Táº£i dá»¯ liá»‡u
# ======================================
# def fetch_data(url):
#     print("ğŸ”„ Äang táº£i dá»¯ liá»‡u...")
#     response = requests.get(url)
#     response.raise_for_status()
#     data = response.json()
#     print(f"âœ… ÄÃ£ táº£i {len(data)} báº£n ghi.")
#     return data
#
#
# # ======================================
# # ğŸ§  Gom nhÃ³m dá»¯ liá»‡u
# # ======================================
# def group_data(data):
#     grouped = defaultdict(list)
#     for item in data:
#         pid = item.get("patient_id")
#         sid = item.get("study_id")
#         seid = item.get("series_id")
#         if not all([pid, sid, seid]):
#             continue
#         # Hash tag {pid} Ä‘á»ƒ key cÃ¹ng bá»‡nh nhÃ¢n náº±m cÃ¹ng node
#         key = f"patient:{{{pid}}}:{sid}:{seid}"
#         grouped[key].append(item)
#     print(f"âœ… Gom Ä‘Æ°á»£c {len(grouped)} nhÃ³m dá»¯ liá»‡u.")
#     # ======================================
#     # ğŸ§® TÃ­nh dung lÆ°á»£ng tá»«ng nhÃ³m
#     # ======================================
#     total_size_bytes = 0
#     for key, value in grouped.items():
#         json_str = json.dumps(value)
#         size_bytes = len(json_str.encode('utf-8'))
#         size_mb = size_bytes / (1024 * 1024)
#         total_size_bytes += size_bytes
#         print(f"Key: {key}, Items: {len(value)}, Size: {size_mb:.2f} MB")
#
#     total_size_mb = total_size_bytes / (1024 * 1024)
#     print(f"\nğŸ§  Tá»•ng dung lÆ°á»£ng dá»± kiáº¿n cho {len(grouped)} nhÃ³m: {total_size_mb:.2f} MB")
#     return grouped
#
#
# # ======================================
# # ğŸ’¾ Ghi trá»±c tiáº¿p tá»«ng key vÃ o Redis
# # ======================================
# def save_to_redis_direct(grouped):
#     total_keys = len(grouped)
#     print(f"ğŸ’¾ Báº¯t Ä‘áº§u ghi {total_keys} keys vÃ o Redis Cluster...")
#
#     start_time = time.time()
#     keys_written = 0
#
#     for key, value in grouped.items():
#         try:
#             r.set(key, json.dumps(value))
#             keys_written += 1
#             if keys_written % 100 == 0 or keys_written == total_keys:
#                 print(f"  âœ… ÄÃ£ ghi {keys_written}/{total_keys} keys")
#         except Exception as e:
#             print(f"âŒ Lá»—i khi ghi key {key}: {e}")
#
#     duration = time.time() - start_time
#     rate = total_keys / duration if duration > 0 else total_keys
#     print(f"âœ… HoÃ n táº¥t ghi {total_keys} keys trong {duration:.2f}s ({rate:.2f} keys/s)")
#
#     mem_info = r.info("memory")
#     print(f"ğŸ§  Tá»•ng dung lÆ°á»£ng Redis Ä‘ang dÃ¹ng: {mem_info['used_memory_human']}")
#
#
# # ======================================
# ğŸš€ MAIN
# ======================================
def main():
    # data = fetch_data(URL)
    # grouped = group_data(data)
    # save_to_redis_direct(grouped)
    print("\nğŸ¯ HoÃ n táº¥t ghi dá»¯ liá»‡u vÃ o Redis Cluster.")


if __name__ == "__main__":
    main()
